%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                   Comparisons                               %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Classification Model}\label{compare}

\begin{pycode}[manager_ml]
manager_ml = texfigure.Manager(
    pytex, './',
    python_dir='python',
    fig_dir='figures',
    data_dir='data',
    number=4,
)
from formatting import heating_palette, heating_cmap
from classify import prep_data, classify_ar
X, Y, X_observation, bad_pixels = prep_data(
    manager_ml.data_dir,
    channel_pairs,
    heating,
    correlation_threshold=correlation_threshold,
    rsquared_threshold=rsquared_threshold,
    scale_slope=False,
    scale_timelag=False,
    scale_correlation=False,
)
# Dummy metadata for creating maps
meta = Map(os.path.join(manager_ml.data_dir, 'observations', 'timelag_171_131.fits')).meta

# ML classification code here
rf_options = {
    'n_estimators': 100,
    'max_features': 'sqrt',
    'criterion': 'gini',
    'max_depth': 25,
    'min_samples_leaf': 1,
    'min_samples_split': 2,
    'bootstrap': True,
    'oob_score': True,
    'max_leaf_nodes': None,
    'min_impurity_decrease': 0,
    'n_jobs': -1,
}
frequency_maps = {}
probability_maps = {}
test_error = {}

# EM slope only
f_map, p_maps, _, err = classify_ar(rf_options, X[:,-1:], Y, X_observation[:,-1:], bad_pixels,)
frequency_maps['a'] = f_map
probability_maps['a'] = p_maps
test_error['a'] = err

# Timelags, cross-correlation only
f_map, p_maps, _, err = classify_ar(rf_options, X[:,:-1], Y, X_observation[:,:-1], bad_pixels)
frequency_maps['b'] = f_map
probability_maps['b'] = p_maps
test_error['b'] = err

# EM slope, timelags, cross-correlation
f_map, p_maps, clf, err = classify_ar(rf_options, X, Y, X_observation, bad_pixels)
frequency_maps['c'] = f_map
probability_maps['c'] = p_maps
test_error['c'] = err

# Calculate feature importances
importances = clf.feature_importances_
i_important = np.argsort(importances)[::-1]
std = np.std([t.feature_importances_ for t in clf.estimators_], axis=0)

# Top 10 features
f_map, p_maps, _, err = classify_ar(rf_options, X[:, i_important[:10]], Y,
                                    X_observation[:, i_important[:10]], bad_pixels)
frequency_maps['d'] = f_map
probability_maps['d'] = p_maps
test_error['d'] = err
\end{pycode}

% Describe random forest technique
% how is data prepared
% what is the RF actually doing
% weaknesses and assumptions

To systematically assess whether the observed emission measure slopes and timelags of NOAA 1158 are consistent with high-, intermediate-, or low-frequency heating, we train a random forest classifier on our predicted emission measure slopes and timelags from \citetalias{barnes_understanding_2019}. We then use our trained model to classify each

\subsection{Different Feature Combinations}

\begin{pycode}[manager_ml]
cases = ['a','b','c','d']
tab = {
    'Case': [c.upper() for c in cases],
    'Parameters': [r'$a$', r'$\tau_{AB},\mathcal{C}_{AB}$', r'$a,\tau_{AB},\mathcal{C}_{AB}$', r'Top 10 features from \autoref{tab:importance}'],
    'Error': [test_error[c] for c in cases],
    'High': [frequency_maps[c][frequency_maps[c] == 0].size/frequency_maps[c][~np.isnan(frequency_maps[c])].size for c in cases],
    'Intermediate': [frequency_maps[c][frequency_maps[c] == 1].size/frequency_maps[c][~np.isnan(frequency_maps[c])].size for c in cases],
    'Low': [frequency_maps[c][frequency_maps[c] == 2].size/frequency_maps[c][~np.isnan(frequency_maps[c])].size for c in cases],
}
caption = r'Misclassification error as evaluated on the test data set and percentage of pixels labeled as each class for the three different combinations of diagnostics.\label{tab:cases}'
formats = {
    'Error': '%.2f',
    'High': '%.3f',
    'Intermediate': '%.3f',
    'Low': '%.3f'
}
with io.StringIO() as f:
    ascii.write(tab, format='aastex', caption=caption, output=f, formats=formats)
    table = f.getvalue()
\end{pycode}
\py[manager_ml]|table|

%Run classifier for EM, timelag+correlation, EM+timelag+correlation;
% compare results
% show heating frequency maps, probability maps for all three cases

\begin{pycode}[manager_ml]
fig = plt.figure(figsize=texfigure.figsize(
    pytex,
    scale=1 if is_onecolumn() else 2,
    height_ratio=4/3*0.965,
    figure_width_context='columnwidth'
))
axes = []
for j,c in enumerate(('a','b','c','d')):
    for i,h in enumerate(heating):
        m = GenericMap(probability_maps[c][h], meta)
        m = m.submap(SkyCoord(Tx=-410*u.arcsec,Ty=-325*u.arcsec,frame=m.coordinate_frame),
                     SkyCoord(Tx=-225*u.arcsec,Ty=-150*u.arcsec,frame=m.coordinate_frame))
        ax = fig.add_subplot(4, 3, 3*j+i+1, projection=m)
        axes.append(ax)
        im = m.plot(axes=ax, annotate=False, title=False, vmin=0, vmax=1, cmap='viridis',)
        ax.grid(alpha=0)
        lon,lat = ax.coords
        lon.set_ticks(number=4)
        lat.set_ticks(number=2)
        if i == 0 and j==3:
            lon.set_axislabel('Helioprojective Longitude',)
            lat.set_axislabel('Helioprojective Latitude', )
            lat.set_ticklabel(rotation='vertical')
        else:
            lat.set_ticklabel_visible(False)
            lon.set_ticklabel_visible(False)
        if i == 0:
            xtext,ytext = m.world_to_pixel(SkyCoord(-400*u.arcsec,-165*u.arcsec,frame=m.coordinate_frame))
            ax.text(int(xtext.value), int(ytext.value), f'{c.capitalize()}', color='k', fontsize=plt.rcParams['legend.fontsize'])
        if j == 0:
            xtext,ytext = m.world_to_pixel(SkyCoord(-235*u.arcsec,-315*u.arcsec,frame=m.coordinate_frame))
            ax.text(int(xtext.value), int(ytext.value),
                    h.split('_')[0].capitalize(),
                    horizontalalignment='right',
                    verticalalignment='bottom',
                    color='k', fontsize=plt.rcParams['legend.fontsize'])
plt.subplots_adjust(wspace=0.03,hspace=0.03)
cax = fig.add_axes([
    axes[0].get_position().get_points()[0,0],
    axes[0].get_position().get_points()[1,1]+0.0075,
    axes[-1].get_position().get_points()[1,0] - axes[0].get_position().get_points()[0,0],
    0.015
])
cbar = fig.colorbar(im, cax=cax, orientation='horizontal')
cbar.ax.xaxis.set_ticks_position('top')
### Save ###
fig_probability_maps = manager_ml.save_figure('probability-maps')
fig_probability_maps.caption = r'Probability maps for each case and each heating frequency'
fig_probability_maps.figure_env_name = 'figure*'
fig_probability_maps.figure_width = r'\columnwidth' if is_onecolumn() else r'2\columnwidth'
fig_probability_maps.fig_str = fig_str
\end{pycode}
\py[manager_ml]|fig_probability_maps|

\begin{pycode}[manager_ml]
fig = plt.figure(figsize=texfigure.figsize(
    pytex,
    scale=1 if is_onecolumn() else 2,
    height_ratio=0.965,
    figure_width_context='columnwidth'
))
axes = []
for i,c in enumerate(('a','b','c','d')):
    m = GenericMap(frequency_maps[c],meta)
    m = m.submap(SkyCoord(Tx=-410*u.arcsec,Ty=-325*u.arcsec,frame=m.coordinate_frame),
                 SkyCoord(Tx=-225*u.arcsec,Ty=-150*u.arcsec,frame=m.coordinate_frame))
    ax = fig.add_subplot(2, 2, i+1, projection=m)
    axes.append(ax)
    im = m.plot(axes=ax, title=False,annotate=False, vmin=-0.5, vmax=2.5, cmap=heating_cmap())
    ax.grid(alpha=0)
    # Axes and ticks
    lon, lat = ax.coords
    if i == 2:
        lon.set_axislabel('Helioprojective Longitude',)
        lat.set_axislabel('Helioprojective Latitude',)
        lat.set_ticklabel(rotation='vertical')
    else:
        lon.set_ticklabel_visible(False)
        lat.set_ticklabel_visible(False)
    lon.set_ticks(number=4)
    lat.set_ticks(number=2)
    xtext,ytext = m.world_to_pixel(SkyCoord(-400*u.arcsec,-165*u.arcsec,frame=m.coordinate_frame))
    ax.text(int(xtext.value), int(ytext.value), f'{c.capitalize()}', color='k', fontsize=plt.rcParams['legend.fontsize'])
plt.subplots_adjust(wspace=0.03,hspace=0.03)
# Colorbar
cax = fig.add_axes([
    axes[0].get_position().get_points()[0,0],
    axes[0].get_position().get_points()[1,1] + 0.01,
    axes[-1].get_position().get_points()[1,0] - axes[0].get_position().get_points()[0,0],
    0.02
])
cbar = fig.colorbar(im, cax=cax,orientation='horizontal')
cbar.ax.xaxis.set_ticks_position('top')
cbar.set_ticks([-0.25,1,2.25])
cbar.ax.set_xticklabels([h.split('_')[0].capitalize() for h in heating],)
cbar.ax.tick_params(axis='x', which='both', length=0)
# Save
fig_frequency_maps = manager_ml.save_figure('frequency-maps')
fig_frequency_maps.caption = r'Heating frequency maps'
fig_frequency_maps.figure_env_name = 'figure*'
fig_frequency_maps.figure_width = r'\columnwidth' if is_onecolumn() else r'2\columnwidth'
fig_frequency_maps.fig_str = fig_str
\end{pycode}
\py[manager_ml]|fig_frequency_maps|

\subsection{Feature Importance}\label{sec:feature-importance}

% Talk about feature importance, give expression using the Gini importance, Gini impurity
% Discuss results from fourth case
% what does this say about the importance of these variables?

\begin{pycode}[manager_ml]
all_labels = np.array([r'$\tau_{{{},{}}}$'.format(*cp) for cp in channel_pairs] +
                    [r'$\mathcal{{C}}_{{{},{}}}$'.format(*cp) for cp in channel_pairs] + [r'$a$'])
tab = {
    'Feature': all_labels[i_important[:10]],
    'Importance': importances[i_important[:10]],
    r'$\sigma$': std[i_important[:10]],
}
caption = r'Ten most important features as determined by the random forest classifier in case C. $\sigma$ is the standard deviation of the feature importance of all trees in the random forest. \label{tab:importance}'
formats = { 'Importance': '%.4f', r'$\sigma$': '%.4f' }
with io.StringIO() as f:
    ascii.write(tab, format='aastex', caption=caption, output=f, formats=formats)
    table = f.getvalue()
\end{pycode}
\py[manager_ml]|table|
